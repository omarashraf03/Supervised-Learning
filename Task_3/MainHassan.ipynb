{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4374e0a4",
   "metadata": {},
   "source": [
    "# Speaker Recognition with Naïve Bayes and Bagging Ensemble\n",
    "This notebook performs speaker recognition using audio data from two speakers: **George** and **Jackson**. It includes:\n",
    "- Audio preprocessing using `librosa`\n",
    "- Feature extraction (MFCCs, Spectral Rolloff, ZCR)\n",
    "- Implementation of a **Naïve Bayes classifier from scratch**\n",
    "- Evaluation against `scikit-learn`'s `GaussianNB`\n",
    "- Implementation of **Bagging Ensemble** with Naïve Bayes and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9016797",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd079333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.effects\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a79beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "george_folder = '/Users/hassa/Desktop/GDG/Supervised-Learning/Task_3/george'\n",
    "jackson_folder = '/Users/hassa/Desktop/GDG/Supervised-Learning/Task_3/jackson'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b686e9f",
   "metadata": {},
   "source": [
    "# Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0fb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path):\n",
    "    try:\n",
    "        signal, sr = librosa.load(file_path)\n",
    "        \n",
    "        signal, _ = librosa.effects.trim(signal)  \n",
    "        \n",
    "        signal = librosa.util.normalize(signal)\n",
    "        \n",
    "        return signal, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f243ad",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8013c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    signal, sr = preprocess_audio(file_path)\n",
    "    if signal is None:\n",
    "        return None\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)  \n",
    "    mfccs = np.mean(mfccs.T, axis=0)  \n",
    "    \n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=signal, sr=sr)[0]  \n",
    "    zcr = librosa.feature.zero_crossing_rate(y=signal)[0]  \n",
    "    \n",
    "    features = np.hstack([mfccs, spectral_rolloff.mean(), zcr.mean()])\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1f2d2",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffb6670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>mfcc_13</th>\n",
       "      <th>spectral_rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-246.137878</td>\n",
       "      <td>216.687088</td>\n",
       "      <td>-38.796513</td>\n",
       "      <td>8.815818</td>\n",
       "      <td>13.374378</td>\n",
       "      <td>-47.711304</td>\n",
       "      <td>-13.927596</td>\n",
       "      <td>-8.828659</td>\n",
       "      <td>-29.201393</td>\n",
       "      <td>-2.409600</td>\n",
       "      <td>-1.546351</td>\n",
       "      <td>-13.657865</td>\n",
       "      <td>-7.672847</td>\n",
       "      <td>1478.991057</td>\n",
       "      <td>0.044742</td>\n",
       "      <td>jackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-272.251190</td>\n",
       "      <td>166.416351</td>\n",
       "      <td>-99.521530</td>\n",
       "      <td>16.647449</td>\n",
       "      <td>36.567478</td>\n",
       "      <td>-48.509678</td>\n",
       "      <td>-21.056341</td>\n",
       "      <td>-36.550667</td>\n",
       "      <td>-49.181263</td>\n",
       "      <td>7.645572</td>\n",
       "      <td>-18.115288</td>\n",
       "      <td>-42.182991</td>\n",
       "      <td>4.148391</td>\n",
       "      <td>2659.350586</td>\n",
       "      <td>0.083696</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-251.647247</td>\n",
       "      <td>160.244904</td>\n",
       "      <td>-44.033691</td>\n",
       "      <td>10.318113</td>\n",
       "      <td>5.280222</td>\n",
       "      <td>-44.314095</td>\n",
       "      <td>4.977806</td>\n",
       "      <td>-4.780592</td>\n",
       "      <td>-45.944427</td>\n",
       "      <td>-14.767281</td>\n",
       "      <td>-19.791658</td>\n",
       "      <td>-44.414085</td>\n",
       "      <td>-17.324881</td>\n",
       "      <td>1939.334106</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-274.095917</td>\n",
       "      <td>175.837616</td>\n",
       "      <td>-111.480713</td>\n",
       "      <td>13.345282</td>\n",
       "      <td>32.131676</td>\n",
       "      <td>-52.038898</td>\n",
       "      <td>-15.786862</td>\n",
       "      <td>-38.824608</td>\n",
       "      <td>-55.343140</td>\n",
       "      <td>11.196049</td>\n",
       "      <td>-17.315891</td>\n",
       "      <td>-47.920212</td>\n",
       "      <td>5.411440</td>\n",
       "      <td>2849.919434</td>\n",
       "      <td>0.104761</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-193.464005</td>\n",
       "      <td>186.775986</td>\n",
       "      <td>-85.782654</td>\n",
       "      <td>-2.213060</td>\n",
       "      <td>-1.627923</td>\n",
       "      <td>-74.069504</td>\n",
       "      <td>-9.857377</td>\n",
       "      <td>-6.227119</td>\n",
       "      <td>-53.334595</td>\n",
       "      <td>-18.015398</td>\n",
       "      <td>-14.073372</td>\n",
       "      <td>-32.152668</td>\n",
       "      <td>-5.531947</td>\n",
       "      <td>2535.534668</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mfcc_1      mfcc_2      mfcc_3     mfcc_4     mfcc_5     mfcc_6  \\\n",
       "0 -246.137878  216.687088  -38.796513   8.815818  13.374378 -47.711304   \n",
       "1 -272.251190  166.416351  -99.521530  16.647449  36.567478 -48.509678   \n",
       "2 -251.647247  160.244904  -44.033691  10.318113   5.280222 -44.314095   \n",
       "3 -274.095917  175.837616 -111.480713  13.345282  32.131676 -52.038898   \n",
       "4 -193.464005  186.775986  -85.782654  -2.213060  -1.627923 -74.069504   \n",
       "\n",
       "      mfcc_7     mfcc_8     mfcc_9    mfcc_10    mfcc_11    mfcc_12  \\\n",
       "0 -13.927596  -8.828659 -29.201393  -2.409600  -1.546351 -13.657865   \n",
       "1 -21.056341 -36.550667 -49.181263   7.645572 -18.115288 -42.182991   \n",
       "2   4.977806  -4.780592 -45.944427 -14.767281 -19.791658 -44.414085   \n",
       "3 -15.786862 -38.824608 -55.343140  11.196049 -17.315891 -47.920212   \n",
       "4  -9.857377  -6.227119 -53.334595 -18.015398 -14.073372 -32.152668   \n",
       "\n",
       "     mfcc_13  spectral_rolloff  zero_crossing_rate    label  \n",
       "0  -7.672847       1478.991057            0.044742  jackson  \n",
       "1   4.148391       2659.350586            0.083696   george  \n",
       "2 -17.324881       1939.334106            0.037842   george  \n",
       "3   5.411440       2849.919434            0.104761   george  \n",
       "4  -5.531947       2535.534668            0.058419   george  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "# Process the George folder\n",
    "for filename in os.listdir(george_folder):\n",
    "    file_path = os.path.join(george_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            data.append(features)\n",
    "            labels.append('george')\n",
    "\n",
    "# Process the Jackson folder\n",
    "for filename in os.listdir(jackson_folder):\n",
    "    file_path = os.path.join(jackson_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            data.append(features)\n",
    "            labels.append('jackson')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = labels\n",
    "\n",
    "\n",
    "feature_columns = [f\"mfcc_{i+1}\" for i in range(13)] + [\"spectral_rolloff\", \"zero_crossing_rate\"]\n",
    "df.columns = feature_columns + ['label']\n",
    "\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = df.drop(columns='label')\n",
    "y = df['label']\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12bebdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (1000, 16)\n",
      "number of samples: 1000\n",
      "df columns: Index(['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7',\n",
      "       'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13',\n",
      "       'spectral_rolloff', 'zero_crossing_rate', 'label'],\n",
      "      dtype='object')\n",
      "df labels: label\n",
      "jackson    500\n",
      "george     500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"df shape:\", df.shape)\n",
    "print(\"number of samples:\", len(df))\n",
    "print(\"df columns:\", df.columns)\n",
    "print(\"df labels:\", df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab39804",
   "metadata": {},
   "source": [
    "# Naïve Bayes Classifier from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaïveBayes:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.priors = {}\n",
    "        self.mean_dict = {}\n",
    "        self.std_dict = {}\n",
    "\n",
    "    def mean(self,X):\n",
    "        return np.sum(X,axis=0) / X.shape[0]\n",
    "    \n",
    "    def std(self,X,mean):\n",
    "        return np.sum((X-mean)**2, axis=0) / X.shape[0]\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        X = np.array(X, dtype=np.float64)\n",
    "        Y = np.array(Y)\n",
    "\n",
    "        self.classes = np.unique(Y)\n",
    "        for Class in self.classes:\n",
    "            X_class = X[Y == Class]\n",
    "            self.priors[Class] = X_class.shape[0] / X.shape[0]\n",
    "            self.mean_dict[Class] = self.mean(X_class)\n",
    "            self.std_dict[Class] = self.std(X_class, self.mean_dict[Class]) + 1e-9\n",
    "\n",
    "    def gaussian_probability(self, X, mean, var):\n",
    "        exponent = np.exp(-((X-mean)**2 )/ (2*var))\n",
    "        return (1/np.sqrt(2*np.pi*var))*exponent\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X = np.array(X, dtype=np.float64)\n",
    "        return np.array([self.predict_single(x) for x in X])   \n",
    "    \n",
    "    def predict_single(self, X):\n",
    "        posteriors=[]\n",
    "        for Class in self.classes:\n",
    "            prior = np.log(self.priors[Class])\n",
    "            class_conditional = np.sum(np.log(self.gaussian_probability(X, self.mean_dict[Class], self.std_dict[Class])))\n",
    "            posterior = prior + class_conditional\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "    \n",
    "    def evaluate(self , y_true , y_pred):\n",
    "        accuracy = np.mean(y_true == y_pred)\n",
    "\n",
    "        classes = np.unique(y_true)\n",
    "        precision, recall, f1 = [], [], []\n",
    "\n",
    "        for cls in classes:\n",
    "            TP = np.sum((y_pred == cls) & (y_true == cls))\n",
    "            FP = np.sum((y_pred == cls) & (y_true != cls))\n",
    "            FN = np.sum((y_pred != cls) & (y_true == cls))\n",
    "\n",
    "            p = TP / (TP + FP + 1e-9)\n",
    "            r = TP / (TP + FN + 1e-9)\n",
    "            f = 2 * p * r / (p + r + 1e-9)\n",
    "\n",
    "            precision.append(p)\n",
    "            recall.append(r)\n",
    "            f1.append(f)\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': np.mean(precision),\n",
    "            'recall': np.mean(recall),\n",
    "            'f1_score': np.mean(f1)\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaae256",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "042fcbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 800\n",
      "Testing set size: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013a94e",
   "metadata": {},
   "source": [
    "# Evaluate Naïve Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6448dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Accuracy : 0.965\n",
      "Precision: 0.966\n",
      "Recall   : 0.965\n",
      "F1 Score : 0.965\n"
     ]
    }
   ],
   "source": [
    "model = NaïveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "results = model.evaluate(y_test, y_pred)\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Accuracy : {results['accuracy']:.3f}\")\n",
    "print(f\"Precision: {results['precision']:.3f}\")\n",
    "print(f\"Recall   : {results['recall']:.3f}\")\n",
    "print(f\"F1 Score : {results['f1_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58b54902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Naïve Bayes Results:\n",
      "Accuracy: 0.965\n",
      "Precision: 0.966\n",
      "Recall: 0.965\n",
      "F1_score: 0.965\n",
      "\n",
      "Scikit-learn GaussianNB Results:\n",
      "Accuracy: 0.965\n",
      "Precision: 0.966\n",
      "Recall: 0.965\n",
      "F1_score: 0.965\n"
     ]
    }
   ],
   "source": [
    "# Custom Naïve Bayes\n",
    "custom_model = NaïveBayes()\n",
    "custom_model.fit(X_train, y_train)\n",
    "y_pred_custom = custom_model.predict(X_test)\n",
    "custom_results = custom_model.evaluate(y_test, y_pred_custom)\n",
    "\n",
    "# Scikit-learn GaussianNB\n",
    "sklearn_model = GaussianNB()\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "y_pred_sklearn = sklearn_model.predict(X_test)\n",
    "\n",
    "sklearn_results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_sklearn),\n",
    "    'precision': precision_score(y_test, y_pred_sklearn, average='macro'),\n",
    "    'recall': recall_score(y_test, y_pred_sklearn, average='macro'),\n",
    "    'f1_score': f1_score(y_test, y_pred_sklearn, average='macro')\n",
    "}\n",
    "\n",
    "def print_results(name, results):\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    for metric, value in results.items():\n",
    "        print(f\"{metric.capitalize()}: {value:.3f}\")\n",
    "\n",
    "print_results(\"Custom Naïve Bayes\", custom_results)\n",
    "print_results(\"Scikit-learn GaussianNB\", sklearn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1a0af",
   "metadata": {},
   "source": [
    "## Bagging Ensemble\n",
    "Use both Naïve Bayes and Logistic Regression with bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a924c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "\n",
    "def baggingEnsamble(baseModel , x_train , y_train, estimators = 10):\n",
    "    models=[]\n",
    "    for i in range(estimators):\n",
    "        x_sample , y_sample = resample(x_train,y_train)\n",
    "        model = baseModel()\n",
    "        model.fit(x_sample , y_sample)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def predictEnsamble(models , X):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X)\n",
    "        predictions.append(y_pred)\n",
    "    predictions = np.array(predictions).T\n",
    "    finalPredictions = [Counter(row).most_common(1)[0][0] for row in predictions]\n",
    "    return finalPredictions\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(\"Accuracy:\", round(accuracy, 4))\n",
    "    print(\"Precision:\", round(precision, 4))\n",
    "    print(\"Recall:\", round(recall, 4))\n",
    "    print(\"F1 Score:\", round(f1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6108f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes:\n",
      "Accuracy: 0.965\n",
      "Precision: 0.9658\n",
      "Recall: 0.9645\n",
      "F1 Score: 0.9649\n",
      "---------------------\n",
      "Logistic Regression:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "NB_models = baggingEnsamble(NaïveBayes , X_train,y_train)\n",
    "y_pred_NB = predictEnsamble(NB_models , X_test)\n",
    "LR_models = baggingEnsamble(lambda: LogisticRegression(max_iter=1000) , X_train,y_train)\n",
    "y_pred_LR = predictEnsamble(LR_models , X_test)\n",
    "\n",
    "print('Naïve Bayes:')\n",
    "evaluate_model(y_test, y_pred_NB)\n",
    "print('---------------------\\nLogistic Regression:')\n",
    "evaluate_model(y_test, y_pred_LR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
